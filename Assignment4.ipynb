{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c2fc0d-c391-48b8-9f52-3deba46e7920",
   "metadata": {},
   "source": [
    "# Investment Strategy Analysis for Inherited Wealth\n",
    "\n",
    "Welcome to this Jupyter Notebook, designed as part of our assignment to develop an investment strategy for an inherited sum of R100,000. This analysis is aimed at identifying the most promising investment avenues through a mix of broad-based unit trusts and exchange-traded funds (ETFs), specifically avoiding single stocks to align with best practices.\n",
    "\n",
    "The objective is to utilize quantitative and qualitative analysis methods to evaluate different markets and asset classes. This will include studying historical performances, applying statistical techniques, and forecasting future returns to make informed investment decisions that could potentially maximize the return on the inherited wealth by the time I reach the age of 60.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662109e-cb29-4b18-af3e-f46560b11778",
   "metadata": {},
   "source": [
    "## Assignment Objectives and Analysis Framework\n",
    "\n",
    "This notebook is structured to systematically analyze various ETFs and indexes using data from the Alpha Vantage API. Here’s what we aim to achieve:\n",
    "\n",
    "1. **Data Collection**:\n",
    "    - Fetch daily time series data, along with technical indicators such as Simple Moving Average (SMA) and Relative Strength Index (RSI) for selected ETFs.\n",
    "    - Incorporate fundamental data to gain deeper insights into each ETF’s characteristics.\n",
    "\n",
    "2. **Quantitative Analysis**:\n",
    "    - Employ descriptive statistics to understand the data’s central tendencies and variability.\n",
    "    - Use linear regression models to predict future trends based on historical data.\n",
    "\n",
    "3. **Qualitative Analysis**:\n",
    "    - Consider external factors such as economic indicators, market conditions, and geopolitical events that could influence the markets.\n",
    "\n",
    "4. **Investment Recommendations**:\n",
    "    - Synthesize the quantitative data and qualitative insights to recommend the most suitable markets for investment.\n",
    "    - Provide a forecast of the potential growth of the investment by the age of 60, illustrating the long-term benefits of the chosen strategy.\n",
    "\n",
    "5. **Innovative Techniques**:\n",
    "    - Explore advanced data visualization tools and statistical techniques that go beyond the basic curriculum to enhance the analysis and presentation.\n",
    "\n",
    "6. **Reflection**:\n",
    "    - Conclude with a reflection on the learning experience, the insights gained about financial markets, the effectiveness of various data analysis techniques, and personal growth in data analysis and programming skills within the scope of this course.\n",
    "\n",
    "The aim is to present our findings in a visually engaging manner using storytelling techniques, effective visuals, and clear, concise data representations in a PowerPoint presentation complemented by this detailed Jupyter Notebook analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151d39d3-b0f8-4b96-acfd-e1889cb3cee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for SPY...\n",
      "Data for SPY fetched successfully!\n",
      "\n",
      "Fetching data for VT...\n",
      "Data for VT fetched successfully!\n",
      "\n",
      "Fetching data for EEM...\n",
      "Data for EEM fetched successfully!\n",
      "\n",
      "Fetching data for GLD...\n",
      "Data for GLD fetched successfully!\n",
      "\n",
      "Fetching data for ICLN...\n",
      "Data for ICLN fetched successfully!\n",
      "\n",
      "Fetching data for VNQ...\n",
      "Data for VNQ fetched successfully!\n",
      "\n",
      "SPY Data Preview:\n",
      "    timestamp    open    high      low   close    volume\n",
      "0  2024-05-03  511.16  512.55  508.560  511.29  72756709\n",
      "1  2024-05-02  504.15  505.89  499.550  505.03  62550179\n",
      "2  2024-05-01  501.38  508.19  499.865  500.35  80242839\n",
      "3  2024-04-30  508.56  509.56  501.980  501.98  77483566\n",
      "4  2024-04-29  510.09  510.75  507.250  510.06  46415449\n",
      "         time      SMA\n",
      "0  2024-05-03  506.773\n",
      "1  2024-05-02  507.130\n",
      "2  2024-05-01  507.532\n",
      "3  2024-04-30  508.485\n",
      "4  2024-04-29  509.328\n",
      "         time      RSI\n",
      "0  2024-05-03  53.8995\n",
      "1  2024-05-02  47.3777\n",
      "2  2024-05-01  41.6470\n",
      "3  2024-04-30  43.1674\n",
      "4  2024-04-29  51.8863\n",
      "{}\n",
      "\n",
      "VT Data Preview:\n",
      "    timestamp    open     high      low   close   volume\n",
      "0  2024-05-03  108.83  109.060  108.280  108.79  1376135\n",
      "1  2024-05-02  107.25  107.845  106.480  107.64  1100134\n",
      "2  2024-05-01  106.42  107.810  106.100  106.34  1521386\n",
      "3  2024-04-30  107.77  107.990  106.500  106.54  3626074\n",
      "4  2024-04-29  108.10  108.300  107.722  108.19   920332\n",
      "         time       SMA\n",
      "0  2024-05-03  107.3150\n",
      "1  2024-05-02  107.3560\n",
      "2  2024-05-01  107.4100\n",
      "3  2024-04-30  107.5855\n",
      "4  2024-04-29  107.7370\n",
      "         time      RSI\n",
      "0  2024-05-03  56.4366\n",
      "1  2024-05-02  50.9555\n",
      "2  2024-05-01  43.4927\n",
      "3  2024-04-30  44.4591\n",
      "4  2024-04-29  53.5800\n",
      "{}\n",
      "\n",
      "EEM Data Preview:\n",
      "    timestamp   open    high      low  close    volume\n",
      "0  2024-05-03  42.34  42.490  42.1700  42.47  31815171\n",
      "1  2024-05-02  41.58  42.190  41.4500  42.09  48855695\n",
      "2  2024-05-01  41.06  41.475  40.9750  41.03  34489455\n",
      "3  2024-04-30  41.18  41.320  40.9900  40.99  32748733\n",
      "4  2024-04-29  41.37  41.580  41.3205  41.57  31041175\n",
      "         time      SMA\n",
      "0  2024-05-03  40.8550\n",
      "1  2024-05-02  40.7940\n",
      "2  2024-05-01  40.7475\n",
      "3  2024-04-30  40.7615\n",
      "4  2024-04-29  40.7760\n",
      "         time      RSI\n",
      "0  2024-05-03  67.4126\n",
      "1  2024-05-02  64.5475\n",
      "2  2024-05-01  54.0927\n",
      "3  2024-04-30  53.6134\n",
      "4  2024-04-29  62.3834\n",
      "{}\n",
      "\n",
      "GLD Data Preview:\n",
      "    timestamp    open      high     low   close    volume\n",
      "0  2024-05-03  212.89  213.2250  210.71  212.96   8679910\n",
      "1  2024-05-02  211.90  213.7050  211.49  213.13   6286967\n",
      "2  2024-05-01  212.96  215.5000  212.41  213.79  10373880\n",
      "3  2024-04-30  213.38  214.1271  211.80  211.87  11248615\n",
      "4  2024-04-29  216.02  217.2150  215.25  216.18   6409870\n",
      "         time       SMA\n",
      "0  2024-05-03  216.7650\n",
      "1  2024-05-02  216.8740\n",
      "2  2024-05-01  216.7935\n",
      "3  2024-04-30  216.7410\n",
      "4  2024-04-29  216.6920\n",
      "         time      RSI\n",
      "0  2024-05-03  50.2592\n",
      "1  2024-05-02  50.6482\n",
      "2  2024-05-01  52.1019\n",
      "3  2024-04-30  48.0761\n",
      "4  2024-04-29  58.2878\n",
      "{'Information': 'Thank you for using Alpha Vantage! Our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
      "\n",
      "ICLN Data Preview:\n",
      "                                                   {\n",
      "0      \"Information\": \"Thank you for using Alpha ...\n",
      "1                                                  }\n",
      "                                                   {\n",
      "0      \"Information\": \"Thank you for using Alpha ...\n",
      "1                                                  }\n",
      "                                                   {\n",
      "0      \"Information\": \"Thank you for using Alpha ...\n",
      "1                                                  }\n",
      "{'Information': 'Thank you for using Alpha Vantage! Our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n",
      "\n",
      "VNQ Data Preview:\n",
      "                                                   {\n",
      "0      \"Information\": \"Thank you for using Alpha ...\n",
      "1                                                  }\n",
      "                                                   {\n",
      "0      \"Information\": \"Thank you for using Alpha ...\n",
      "1                                                  }\n",
      "                                                   {\n",
      "0      \"Information\": \"Thank you for using Alpha ...\n",
      "1                                                  }\n",
      "{'Information': 'Thank you for using Alpha Vantage! Our standard API rate limit is 25 requests per day. Please subscribe to any of the premium plans at https://www.alphavantage.co/premium/ to instantly remove all daily rate limits.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Function to fetch ETF data\n",
    "def fetch_etf_data(symbol, api_key):\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}&datatype=csv'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.content.decode('utf-8')\n",
    "        df = pd.read_csv(io.StringIO(data))\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {symbol}: \", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Fetching Simple Moving Average (SMA)\n",
    "def fetch_sma(symbol, api_key):\n",
    "    sma_url = f'https://www.alphavantage.co/query?function=SMA&symbol={symbol}&interval=daily&time_period=20&series_type=close&apikey={api_key}&datatype=csv'\n",
    "    return fetch_data(sma_url)\n",
    "\n",
    "# Fetching Relative Strength Index (RSI)\n",
    "def fetch_rsi(symbol, api_key):\n",
    "    rsi_url = f'https://www.alphavantage.co/query?function=RSI&symbol={symbol}&interval=daily&time_period=14&series_type=close&apikey={api_key}&datatype=csv'\n",
    "    return fetch_data(rsi_url)\n",
    "\n",
    "# Fetching ETF Overview (Fundamental Data)\n",
    "def fetch_etf_overview(symbol, api_key):\n",
    "    overview_url = f'https://www.alphavantage.co/query?function=OVERVIEW&symbol={symbol}&apikey={api_key}'\n",
    "    response = requests.get(overview_url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to fetch overview for {symbol}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# General function to fetch data from API\n",
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.content.decode('utf-8')\n",
    "        df = pd.read_csv(io.StringIO(data))\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to fetch data: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Your API Key\n",
    "api_key = 'NAESXONQHLPIJRTA'  # Replace YOUR_API_KEY with your actual API key from Alpha Vantage\n",
    "\n",
    "# List of ETF symbols\n",
    "etf_symbols = ['SPY', 'VT', 'EEM', 'GLD', 'ICLN', 'VNQ']\n",
    "\n",
    "# Dictionary to hold data for each ETF\n",
    "etf_data = {}\n",
    "\n",
    "# Fetch data for each ETF\n",
    "for symbol in etf_symbols:\n",
    "    print(f\"\\nFetching data for {symbol}...\")\n",
    "    daily_data = fetch_etf_data(symbol, api_key)\n",
    "    sma_data = fetch_sma(symbol, api_key)\n",
    "    rsi_data = fetch_rsi(symbol, api_key)\n",
    "    overview_data = fetch_etf_overview(symbol, api_key)\n",
    "\n",
    "    if daily_data is not None:\n",
    "        etf_data[symbol] = {\n",
    "            'Daily': daily_data,\n",
    "            'SMA': sma_data,\n",
    "            'RSI': rsi_data,\n",
    "            'Overview': overview_data\n",
    "        }\n",
    "        print(f\"Data for {symbol} fetched successfully!\")\n",
    "    else:\n",
    "        print(f\"Data for {symbol} not available or failed to fetch.\")\n",
    "\n",
    "# Example of how to access the data\n",
    "for symbol, datasets in etf_data.items():\n",
    "    print(f\"\\n{symbol} Data Preview:\")\n",
    "    if datasets['Daily'] is not None:\n",
    "        print(datasets['Daily'].head())  # Display the first few rows of the daily data\n",
    "    if datasets['SMA'] is not None:\n",
    "        print(datasets['SMA'].head())  # Display the first few rows of the SMA data\n",
    "    if datasets['RSI'] is not None:\n",
    "        print(datasets['RSI'].head())  # Display the first few rows of the RSI data\n",
    "    if datasets['Overview'] is not None:\n",
    "        print(datasets['Overview'])  # Display the overview data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36097e72-6079-4dc8-9a46-e52308c27f37",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 60\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Assume 'etf_data' is your DataFrame loaded with data from Alpha Vantage\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m etf_data_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mclean_etf_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metf_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m moving_averages \u001b[38;5;241m=\u001b[39m calculate_moving_averages(etf_data_cleaned)\n\u001b[0;32m     62\u001b[0m etf_data_with_outliers \u001b[38;5;241m=\u001b[39m detect_outliers(etf_data_cleaned)\n",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m, in \u001b[0;36mclean_etf_data\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mCleans ETF data by handling missing values, correcting data types, and removing duplicates.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mDataFrame: The cleaned DataFrame.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Convert date column to datetime format\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Sort data by date\u001b[39;00m\n\u001b[0;32m     16\u001b[0m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_etf_data(df):\n",
    "    \"\"\"\n",
    "    Cleans ETF data by handling missing values, correcting data types, and removing duplicates.\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame containing ETF data.\n",
    "    Returns:\n",
    "    DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert date column to datetime format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    \n",
    "    # Sort data by date\n",
    "    df.sort_values('timestamp', inplace=True)\n",
    "    \n",
    "    # Remove any duplicates\n",
    "    df.drop_duplicates(subset=['timestamp'], keep='last', inplace=True)\n",
    "    \n",
    "    # Fill missing numeric values with the mean\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "    \n",
    "    # Check for any remaining null values and drop if necessary\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def calculate_moving_averages(df, window=20):\n",
    "    \"\"\"\n",
    "    Calculates the moving average of the 'close' price.\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame with stock data.\n",
    "    window (int): The window size to calculate the moving average.\n",
    "    Returns:\n",
    "    Series: A pandas Series containing the moving average of the closing prices.\n",
    "    \"\"\"\n",
    "    return df['close'].rolling(window=window).mean()\n",
    "\n",
    "def detect_outliers(df, n_std=3):\n",
    "    \"\"\"\n",
    "    Identifies outliers in the 'close' price column based on standard deviation.\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame to analyze.\n",
    "    n_std (int): The number of standard deviations to use as a threshold.\n",
    "    Returns:\n",
    "    DataFrame: DataFrame with an additional column 'Outlier' marking outliers as True.\n",
    "    \"\"\"\n",
    "    mean = df['close'].mean()\n",
    "    std = df['close'].std()\n",
    "    \n",
    "    df['Outlier'] = (df['close'] > mean + n_std * std) | (df['close'] < mean - n_std * std)\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# Assume 'etf_data' is your DataFrame loaded with data from Alpha Vantage\n",
    "etf_data_cleaned = clean_etf_data(etf_data)\n",
    "moving_averages = calculate_moving_averages(etf_data_cleaned)\n",
    "etf_data_with_outliers = detect_outliers(etf_data_cleaned)\n",
    "\n",
    "print(etf_data_cleaned.head())\n",
    "print(moving_averages.head())\n",
    "print(etf_data_with_outliers[etf_data_with_outliers['Outlier']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed60c7-4c66-462d-845e-a99e85702443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
